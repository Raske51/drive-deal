# ğŸš— Scraper d'annonces de vÃ©hicules d'occasion

Ce projet permet de rÃ©cupÃ©rer automatiquement des annonces de vÃ©hicules d'occasion depuis plusieurs plateformes populaires :
- âœ… La Centrale
- âœ… LeBonCoin
- âœ… LeParking
- âœ… AutoScout24

## ğŸ“‹ FonctionnalitÃ©s

- âœ… Scraping multi-sources (plusieurs sites de petites annonces)
- âœ… Filtrage par marque, prix, annÃ©e, kilomÃ©trage, etc.
- âœ… TÃ©lÃ©chargement et optimisation des images
- âœ… Stockage des donnÃ©es en JSON ou base de donnÃ©es (MySQL/SQLite)
- âœ… Export des donnÃ©es en CSV ou JSON
- âœ… Planification automatique des tÃ¢ches de scraping
- âœ… Gestion des proxies pour Ã©viter les blocages
- âœ… Rotation des User-Agents pour simuler diffÃ©rents navigateurs

## ğŸ” Sites supportÃ©s et leurs spÃ©cificitÃ©s

### La Centrale
- Filtrage avancÃ© par marque, modÃ¨le, annÃ©e, kilomÃ©trage, prix, etc.
- Extraction des caractÃ©ristiques techniques dÃ©taillÃ©es
- RÃ©cupÃ©ration des images en haute qualitÃ©
- DÃ©tection du type de vendeur (professionnel ou particulier)

### LeBonCoin
- Filtrage par marque, modÃ¨le, prix, annÃ©e, etc.
- Gestion des cookies et des popups
- Extraction des coordonnÃ©es du vendeur
- Support des annonces professionnelles et particuliÃ¨res

### LeParking
- Support multilingue (franÃ§ais, anglais, etc.)
- Filtrage avancÃ© par marque, modÃ¨le, version, etc.
- Extraction des caractÃ©ristiques techniques dÃ©taillÃ©es
- RÃ©cupÃ©ration des annonces internationales

### AutoScout24
- Filtrage avancÃ© par marque, modÃ¨le, version, etc.
- Extraction des caractÃ©ristiques techniques dÃ©taillÃ©es
- Support des annonces professionnelles
- RÃ©cupÃ©ration des images en haute qualitÃ©

## ğŸ› ï¸ PrÃ©requis

- Python 3.8+
- Chrome ou Chromium installÃ© (pour Selenium)
- Pip (gestionnaire de paquets Python)

## ğŸ”§ Installation

1. Cloner ce dÃ©pÃ´t ou tÃ©lÃ©charger les fichiers

2. Installer les dÃ©pendances :
```bash
cd scrapers
pip install -r requirements.txt
```

3. Configurer le fichier `config.json` selon vos besoins (ou utiliser la configuration par dÃ©faut)

## ğŸš€ Utilisation

### Utilisation simplifiÃ©e avec run.py

Le script `run.py` permet de lancer facilement le scraper avec diffÃ©rentes options :

```bash
# Lancer le scraping sur toutes les sources
python run.py scrape

# Lancer le scraping sur une source spÃ©cifique
python run.py scrape --source lacentrale
python run.py scrape --source leboncoin
python run.py scrape --source leparking
python run.py scrape --source autoscout24

# Tester le scraper sur une source spÃ©cifique
python run.py test --source lacentrale --pages 2 --download-images

# Exporter les donnÃ©es en CSV
python run.py export --format csv --output output/export.csv
```

### Utilisation directe des scripts

#### Lancer le scraper pour toutes les sources

```bash
python scraper.py
```

#### Lancer le scraper pour une source spÃ©cifique

```bash
python scraper.py --source lacentrale
```

#### Exporter les donnÃ©es en CSV

```bash
python scraper.py --export csv --output output/export.csv
```

#### Planifier un scraping quotidien

```bash
python scraper.py --schedule
```

#### Tester rapidement le scraper

```bash
python test_scraper.py --source lacentrale --pages 1 --download-images
```

## âš™ï¸ Configuration

Le fichier `config.json` permet de personnaliser le comportement du scraper. Vous pouvez Ã©galement utiliser la classe `ScraperConfig` pour accÃ©der et modifier la configuration programmatiquement.

```json
{
  "sources": ["lacentrale", "leboncoin", "leparking", "autoscout24"],
  "search_params": {
    "brands": ["Renault", "Peugeot", "Citroen", "Volkswagen"],
    "max_price": 30000,
    "max_year": 2023,
    "min_year": 2015,
    "max_km": 150000,
    "fuel_types": ["Essence", "Diesel", "Hybride", "Electrique"],
    "transmission": ["Manuelle", "Automatique"]
  },
  "database": {
    "type": "json",
    "path": "output/cars.json"
  },
  "images": {
    "download": true,
    "max_per_car": 10,
    "path": "output/images"
  },
  "scraping": {
    "delay_between_requests": 2,
    "max_retries": 3,
    "timeout": 30,
    "max_pages_per_source": 5,
    "headless": true
  }
}
```

## ğŸ“ Structure du projet

```
scrapers/
â”œâ”€â”€ run.py               # Script de lancement simplifiÃ©
â”œâ”€â”€ scraper.py           # Script principal
â”œâ”€â”€ config.py            # Fichier de configuration (URLs, headers, user-agents)
â”œâ”€â”€ database.py          # Gestion de la base de donnÃ©es (SQLite ou MySQL)
â”œâ”€â”€ test_scraper.py      # Script de test pour le scraper
â”œâ”€â”€ config.json          # Configuration JSON
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ README.md            # Documentation
â”œâ”€â”€ NEXT_STEPS.md        # Prochaines Ã©tapes du projet
â”œâ”€â”€ output/              # Stockage des fichiers JSON/CSV et images tÃ©lÃ©chargÃ©es
â”‚   â”œâ”€â”€ cars.json        # DonnÃ©es des annonces
â”‚   â””â”€â”€ images/          # Images tÃ©lÃ©chargÃ©es
â”œâ”€â”€ logs/                # Logs du scraper
â”œâ”€â”€ scrapers/            # Modules de scraping spÃ©cifiques
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py  # Classe de base pour tous les scrapers
â”‚   â”œâ”€â”€ lacentrale.py    # Scraper pour La Centrale
â”‚   â”œâ”€â”€ leboncoin.py     # Scraper pour LeBonCoin
â”‚   â”œâ”€â”€ leparking.py     # Scraper pour LeParking (âœ… ImplÃ©mentÃ©)
â”‚   â””â”€â”€ autoscout24.py   # Scraper pour AutoScout24 (âœ… ImplÃ©mentÃ©)
â””â”€â”€ utils/               # Modules utilitaires
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ database.py      # Gestion de la base de donnÃ©es
    â””â”€â”€ image_downloader.py # TÃ©lÃ©chargement et optimisation des images
```

## ğŸ”„ Ajouter un nouveau site

Pour ajouter un nouveau site de petites annonces, suivez ces Ã©tapes :

1. CrÃ©ez une nouvelle classe dans le dossier `scrapers/` qui hÃ©rite de `BaseScraper`
2. ImplÃ©mentez les mÃ©thodes abstraites `_scrape_listings()` et `_scrape_car_details()`
3. Ajoutez la configuration du site dans `site_configs` dans `config.py`
4. Importez et enregistrez votre scraper dans la mÃ©thode `_get_scraper()` de `scraper.py`

Exemple de structure pour un nouveau scraper :

```python
from scrapers.base_scraper import BaseScraper

class MonNouveauScraper(BaseScraper):
    """Scraper pour le site MonNouveauSite"""
    
    def __init__(self, config):
        super().__init__(config)
        # Initialisation spÃ©cifique
    
    def _scrape_listings(self):
        """RÃ©cupÃ¨re les annonces"""
        # ImplÃ©mentation
        return cars
    
    def _scrape_car_details(self, url):
        """RÃ©cupÃ¨re les dÃ©tails d'une annonce"""
        # ImplÃ©mentation
        return car_details
```

## âš ï¸ Avertissement lÃ©gal

Ce scraper est fourni Ã  des fins Ã©ducatives uniquement. L'utilisation de ce scraper doit respecter les conditions d'utilisation des sites web ciblÃ©s. Certains sites web interdisent le scraping de leurs donnÃ©es. Utilisez ce scraper de maniÃ¨re responsable et Ã  vos propres risques.

## ğŸ”„ Maintenance et Ã©volution

Les sites web changent rÃ©guliÃ¨rement leur structure HTML, ce qui peut casser les sÃ©lecteurs CSS utilisÃ©s par le scraper. Si vous rencontrez des problÃ¨mes, vÃ©rifiez les sÃ©lecteurs dans les fichiers de scraping spÃ©cifiques et mettez-les Ã  jour si nÃ©cessaire.

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails. 